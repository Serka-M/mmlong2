#!/bin/bash
# DESCRIPTION: Wrapper script for running mmlong2 pipeline
# AUTHOR: Mantas Sereika (mase@bio.aau.dk)
# LICENSE: GNU General Public License

# Pre-set default settings
set -eo pipefail
script=$(dirname $(which snakemake))
config1=$script/mmlong2-lite-config.yaml
snakefile1=$script/mmlong2-lite.smk
sing1=$script/sing-mmlong2-lite
config2=$script/mmlong2-proc-config.yaml
snakefile2=$script/mmlong2-proc.smk
sing2=$script/sing-mmlong2-proc
version=$(grep version $config2 | cut -d" " -f2 | tr -d '\r')
mode=$(grep mode $config1 | cut -d" " -f2 | tr -d '\r')
fastq=$(grep fastq $config1 | cut -d" " -f2 | tr -d '\r')
sample=$(grep sample $config1 | cut -d" " -f2 | tr -d '\r')
proc=$(grep proc $config1 | cut -d" " -f2 | tr -d '\r')
cov=$(grep reads_diffcov $config1 | cut -d" " -f2 | tr -d '\r')
flye_min_ovlp=$(grep flye_ovlp $config1 | cut -d" " -f2 | tr -d '\r')
flye_min_cov=$(grep flye_cov $config1 | cut -d" " -f2 | tr -d '\r')
medak_mod_pol=$(grep medak_mod_pol $config1 | cut -d" " -f2 | tr -d '\r')
min_contig_len=$(grep min_contig_len $config1 | cut -d" " -f2 | tr -d '\r')
min_mag_len=$(grep min_mag_len $config1 | cut -d" " -f2 | tr -d '\r')
semibin_mod=$(grep semibin_mod $config1 | cut -d" " -f2 | tr -d '\r')
medak_mod_var=$(grep medak_mod_var $config2 | cut -d" " -f2 | tr -d '\r')
db_silva=$(grep db_silva $config2 | cut -d" " -f2 | tr -d '\r')
db_midas=$(grep db_midas $config2 | cut -d" " -f2 | tr -d '\r')
db_gunc=$(grep db_gunc $config2 | cut -d" " -f2 | tr -d '\r')
db_bakta=$(grep db_bakta $config2 | cut -d" " -f2 | tr -d '\r')
db_kaiju=$(grep db_kaiju $config2 | cut -d" " -f2 | tr -d '\r')
db_gtdb=$(grep db_gtdb $config2 | cut -d" " -f2 | tr -d '\r')
stage="OFF"
stages=("OFF" "assembly" "polishing" "binning" "taxonomy" "annotation" "variants")
rule1="Finalise"
rule2="Finalise"
extra1=""
extra2=""
tmp=$(pwd)

# Usage instructions for terminal interface
usage_text="
mmlong2: genome-centric metagenomics workflow using long reads
For issues or feedback please use https://github.com/Serka-M/mmlong2/issues or e-mail to mase@bio.aau.dk 

MAIN INPUTS:
-np	--nanopore_reads	Path to Nanopore reads (default: $fastq)
-pb	--pacbio_reads		Path to PacBio HiFi reads (default: $fastq)
-o	--output_dir		Output directory name (default: $sample)
-p	--processes		Number of processes/multi-threading (default: $proc)
-cov 	--coverage		CSV dataframe for differential coverage binning (e.g. NP/PB/IL,/path/to/reads.fastq)
-run	--run_until		Run pipeline until a specified stage completes (e.g. ${stages[*]/$stage})
 
ADDITIONAL INPUTS:
-tmp	--temporary_dir		Directory for temporary files (default: none)
-med1	--medaka_model_polish	Medaka polishing model (default: $medak_mod_pol)
-med2	--medaka_model_variant	Medaka variant calling model (default: $medak_mod_var)
-sem	--semibin_model		Binning model for SemiBin (default: $semibin_mod)
-fmo	--flye_min_ovlp		Minimum overlap between reads used by Flye assembler (default: auto)
-fmc	--flye_min_cov		Minimum initial contig coverage used by Flye assembler (default: $flye_min_cov)
-mlc	--min_len_contig	Minimum assembly contig length (default: $min_contig_len)
-mlb	--min_len_bin		Minimum genomic bin size (default: $min_mag_len)
-slv	--silva			Silva database to use (default: $db_silva)
-mds	--midas			Midas database to use (default: $db_midas)
-gnc	--gunc			Gunc database to use (default: $db_gunc)
-bkt	--bakta			Bakta database to use (default: $db_bakta)
-kj	--kaiju			Kaiju database to use (default: $db_kaiju)
-gdb	--gtdb			GTDB-tk database to use (default: $db_gtdb)
-x1	--extra_inputs1		Extra inputs for the MAG production part of the Snakemake workflow (default: none)
-x2	--extra_inputs2		Extra inputs for the MAG processing part of the Snakemake workflow (default: none)

MISCELLANEOUS INPUTS:
-h	--help			Print help information
-v	--version		Print workflow version number

"

# Assign inputs
while test $# -gt 0; do
           case "$1" in
                -h | --help) printf -- "$usage_text"; exit 1;;
                -v | --version) printf -- "mmlong2, version $version\n"; exit 1;;
                -np | --nanopore_reads) shift; fastq=$1 && mode="Nanopore-simplex"; shift;;
                -pb | --pacbio_reads) shift; fastq=$1 && mode="PacBio-HiFi"; shift;;
                -o | --output_dir) shift; sample=$1; shift;;
                -p | --processes) shift; proc=$1; shift;;
                -cov | --coverage) shift; cov=$1; shift;;
                -run | --run_until) shift; stage=$1; shift;;
                -tmp | --temporary_dir) shift; tmp=$1; shift;;
                -fmo | --flye_min_ovlp) shift; flye_min_ovlp=$1; shift;;
                -fmc | --flye_min_cov) shift; flye_min_cov=$1; shift;;
                -med1 | --medaka_model_polish) shift; medak_mod_pol=$1; shift;;	
                -med2 | --medaka_model_variant) shift; medak_mod_var=$1; shift;;			
                -mlc | --min_len_contig) shift; min_contig_len=$1; shift;;
                -mlb | --min_len_bin) shift; min_mag_len=$1; shift;;
                -sem | --semibin_model) shift; semibin_mod=$1; shift;;
                -slv | --silva) shift; db_silva=$1; shift;;	
                -mds | --midas) shift; db_midas=$1; shift;;	
                -gnc | --gunc) shift; db_gunc=$1; shift;;	
                -bkt | --bakta) shift; db_bakta=$1; shift;;	
                -kj | --kaiju) shift; db_kaiju=$1; shift;;	
                -gdb | --gtdb) shift; db_gtdb=$1; shift;;	
                -x1 | --extra_inputs1) shift; extra1=$1; shift;;	
                -x2 | --extra_inputs2) shift; extra2=$1; shift;;					
                *)
                   printf "ERROR: $1 is not a recognized input! \nType --help for more information on workflow usage.\n"
                   exit 1;
                   ;;
          esac
  done  

# Basic checks
if [[ ! " ${stages[@]} " =~ " ${stage} " ]]; then echo "ERROR: provided input for early stoppage not recognized" && exit 1; fi
if [ $fastq == "none" ]; then printf -- "$usage_text" && echo "ERROR: Sequencing reads not provided" && exit 1; fi
if [ ! -f $fastq ]; then printf -- "$usage_text" && echo "ERROR: Provided sequencing read file not found" && exit 1; fi
if [ ! $cov == "none" ] && [ ! -f $cov ]; then printf -- "$usage_text" && echo "ERROR: Provided dataframe for differential coverage binning not found" && exit 1; fi
bytes_left="$(df --output=avail -B 1 "$(pwd)" | tail -n 1)" && gigabytes_left=$(($bytes_left/1024**3))
if [ $gigabytes_left -lt 100 ]; then  echo "ERROR: Less than 100 GB of free space left in working directory" && exit 1; else echo "$gigabytes_left GB of free space available in working directory"; fi
if ! command -v snakemake &> /dev/null; then echo "ERROR: Dependency (((snakemake))) could not be found" && exit 1; fi
if ! command -v singularity &> /dev/null; then echo "ERROR: Dependency (((singularity))) could not be found" && exit 1; fi
if ! command -v dirname &> /dev/null; then echo "ERROR: Dependency (((dirname))) could not be found" && exit 1; fi

# Configure early stoppage
if [ $stage == "assembly" ]; then rule1="Assembly" && rule2="OFF"; fi
if [ $stage == "polishing" ]; then rule1="Polishing" && rule2="OFF"; fi
if [ $stage == "binning" ]; then rule2="OFF"; fi
if [ $stage == "taxonomy" ]; then rule2="Taxonomy_aggregate"; fi
if [ $stage == "annotation" ]; then rule2="Annotation_aggregate"; fi
if [ $stage == "variants" ]; then rule2="ExtraQC_microdiversity"; fi

# Configure input paths
if [[ "$sample" = /* ]]; then sample="$(basename $sample)"; fi
if [[ ! "$fastq" = /* ]]; then fastq="$(pwd)/$fastq"; fi
if [[ ! "$tmp" = /* ]]; then tmp="$(pwd)/$tmp"; fi
export TMPDIR=$tmp

# Configure Singularity bindings for MAG production workflow
singularity_binds="-B $(pwd) -B $TMPDIR -B $(dirname $fastq) "
if [ ! $cov == "none" ]; then singularity_binds=$(echo "$singularity_binds -B $(dirname $cov)"); fi
if [ ! $cov == "none" ]; then while read line || [ -n "$line" ]; do
	type="$(echo $line | cut -f1 -d",")"
	reads="$(echo $line | cut -f2 -d",")"
	if [[ ! -f "$reads" ]]; then printf "ERROR: provided read file for differential coverage binning not found \n$reads\n" && exit 1; fi;
	if [[ ! "$type" = "PB" ]] && [[ ! "$type" = "IL" ]] && [[ ! "$type" = "NP" ]]; then printf "ERROR: unrecognised read type for differential coverage binning\n $type with $reads\n" && exit 1; fi;
	singularity_binds=$(echo "$singularity_binds -B $(dirname $reads)")
done < $cov; fi;

# Run snakemake workflow for MAG production 
if [ ! -f $sample/tmp/binning/bins_mmlong2-lite.tsv ]; then
echo "Starting Snakemake workflow (MAG production) for $mode reads and $proc multi-threading instances..."
snakemake --use-singularity --use-conda --singularity-args "$singularity_binds" --cores 1 --nolock -s $snakefile1 --configfile $config1 -R $rule1 --until $rule1 --config sing=$sing1 sample=$sample fastq=$fastq proc=$proc mode=$mode reads_diffcov=$cov flye_ovlp=$flye_min_ovlp flye_cov=$flye_min_cov medak_mod_pol=$medak_mod_pol min_contig_len=$min_contig_len min_mag_len=$min_mag_len semibin_mod=$semibin_mod $extra1; fi

# Database checks
if [ ! -f $db_silva ]; then echo "ERROR: Provided SILVA database not found at $db_silva" && exit 1; fi
if [ ! -f $db_midas ]; then echo "ERROR: Provided MiDAS database not found at $db_midas" && exit 1; fi
if [ ! -f $db_gunc ]; then echo "ERROR: Provided GUNC database not found at $db_gunc" && exit 1; fi
if [ ! -d $db_kaiju ]; then echo "ERROR: Provided Kaiju database not found at $db_kaiju" && exit 1; fi
if [ ! -d $db_gtdb ]; then echo "ERROR: Provided GTDB-tk database not found at $db_gtdb" && exit 1; fi
if [ ! -d $db_bakta ]; then echo "ERROR: Provided Bakta database not found at $db_bakta" && exit 1; fi

# Run snakemake workflow for MAG processing
if [ ! $rule2 == "OFF" ]; then
singularity_binds="-B $(pwd) -B $TMPDIR -B $(dirname $fastq) -B $(dirname $db_silva) -B $(dirname $db_midas) -B $(dirname $db_gunc) -B $db_bakta -B $db_gtdb -B $db_kaiju"
snakemake --use-singularity --use-conda --singularity-args "$singularity_binds" --cores 1 --nolock -s $snakefile2 --configfile $config2 -R $rule2 --until $rule2 --config sing=$sing2 sample=$sample fastq=$fastq proc=$proc mode=$mode medak_mod_var=$medak_mod_var db_silva=$db_silva db_midas=$db_midas db_gunc=$db_gunc db_bakta=$db_bakta db_kaiju=$db_kaiju db_gtdb=$db_gtdb $extra2; fi

# Result info for early stoppage
if [ $stage == "taxonomy" ]; then echo "End of partial workflow. Taxonomic classification results can be found at $sample/tmp/taxonomy"; fi
if [ $stage == "annotation" ]; then echo "End of partial workflow. Annotation results can be found at $sample/tmp/annotation"; fi
if [ $stage == "variants" ]; then echo "End of partial workflow. Variant calling results can be found at $sample/tmp/extra_qc"; fi
exit 0
